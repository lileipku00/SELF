\documentclass{softwaremanual}

\usepackage{titling}

% Figures and controlling packages
\usepackage{float}
\usepackage{wrapfig}


% logo for the title page
\newcommand{\swlogo}{{\includegraphics[width=0.25\textwidth]{../images/shallowWater.png}}
}


\author{Joseph Schoonover}
\date{}

\begin{document}
\frontmatter
% Doing a custom title-page
\begin{titlingpage}
    
        \vspace*{2cm}

   % Setup up the main and sub-titles with the logo
   {\fontfamily{cmss}\selectfont
   \begin{center}
     \HUGE{\textbf{ Spectral Element Libraries in Fortran (SELF) }}\\

     \huge{\textbf{\textcolor{blue}{Shallow Water Equations}}}
   \end{center}
    }    
 
        \vspace{1cm}
        
        \begin{center}
         \swlogo
        \end{center}
        
        \vspace{2cm}
        
     \begin{center}
     
        %Do a subtitle here if you like
        {\fontfamily{cmss}\selectfont
        \huge{
           PCSRI Projects
        }
        
        \vspace{1.5cm}
        
        % Enter the author's name
        \textbf{
        \large{
           \theauthor 
         }}}
        
        \vfill
        
        
     \end{center}
        
    
\end{titlingpage}


{\fontfamily{cmss}\selectfont
\tableofcontents
}
\mainmatter

% Special Style
\pagestyle{myheadings}

\chapter*{Abstract}


\chapter{Background and Motivation}

\section{The Conservative Shallow Water Equations}
The inviscid shallow water equations are a system of coupled partial differential equations that is hyperbolic. The Nodal Discontinuous Galerkin Spectral Element Method (NDGSEM) is well suited for hyperbolic systems. It is highly accurate through its use of arbitrarily high order piecewise polynomial representation of the approximated solution and geometry. It is well known for exhibiting minimal numerical dispersion and dissipation errors for linear problems. It additionally allows for a flexible treatment of the geometry through the use of a structured or unstructured arrangement of \textit{spectral elements} that can represent boundaries through high order polynomial interpolants. The discretization yields dense and local matrix-vector multiplies for computing derivatives and only requires nearest neighbor communication to calculate exchanges between elements. This last property makes the NDGSEM trivial to parallelize. For these reasons, the NDGSEM is applied to the shallow water equation systems \eqref{eq:conservative}, \eqref{eq:skewsymmetric}, and \eqref{eq:linear} to demonstrate its accuracy and scalability for a system of equations that hold many of the important dynamics in geophysics. 

\section{Flavors of the Shallow Water Equations}
The nonlinear shallow water equations can be written in either ``conservative'' (Eqs. \ref{eq:conservative}) or ``skew-symmetric'' (Eqs. \ref{eq:skewsymmetric}) form :
\begin{subequations}
\begin{align}
U_t  + \nabla \cdot \left( \frac{\vec{U}U}{h + \eta} + g \left(h + \frac{\eta}{2} \right)\eta\hat{x} \right) - fV &= g\eta h_x  + q_U\\
V_t  + \nabla \cdot \left( \frac{\vec{U}V}{h + \eta} + g \left(h + \frac{\eta}{2} \right)\eta\hat{y} \right) + fU &= g\eta h_y + q_V\\
\eta_t + \nabla \cdot \vec{U} &= q_\eta
\end{align}\label{eq:conservative}
\end{subequations}

\begin{subequations}
\begin{align}
u_t  + \nabla \cdot \left( (e + p)\hat{x} \right) - (f+\zeta)v &=  q_u\\
v_t  + \nabla \cdot \left( (e + p)\hat{y} \right) + (f+\zeta)u &=  q_v\\
p_t + \nabla \cdot ( (gh+p)\vec{u} ) &= q_p 
\end{align}\label{eq:skewsymmetric}
\end{subequations}
For either system, and throughout the rest of this documentation the symbols have the following meaning :
\begin{itemize}
\item[] $x, y$ : Cartesian coordinate positions ($Length$)
\item[] $t$    : Time
\item[] $U, V$ : The $x,y$ components of the the fluid \textit{transport} ($\frac{Length^2}{Time}$) 
\item[] $H$    : The total fluid thickness, bathymetric plus free surface ($Length$)
\item[] $h$    : Resting fluid depth, the fluid bathymetry ($Length$)
\item[] $g$    : Local acceleration of gravity ($\frac{Length}{Time^2}$)
\item[] $f$    : Coriolis parameter ($Time^{-1}$)
\item[] $u,v$  : The $x,y$ components of the \textit{depth average} fluid velocity ($\frac{Length}{Time}$)
\item[] $e$    : The kinetic energy of the depth averaged velocity field ($\frac{Length^2}{Time^2}$)
\item[] $p$    : Barotropic pressure, the product of gravitational acceleration and free surface anomaly ($\frac{Length^2}{Time^2}$)
\item[] $\zeta$ : The relative vorticity of the depth averaged velocity field ($Time^{-1}$)
\item[] $q_{\phi}$ : Any additional non-conservative source for the variable $\phi$ ($\frac{\phi}{Time}$) 
\end{itemize}

The linear shallow water equations \eqref{eq:linear} are given as
\begin{subequations}
\begin{align}
u_t  + \nabla \cdot \left( p\hat{x} \right) - fv &=  q_u\\
v_t  + \nabla \cdot \left( p\hat{y} \right) + fu &=  q_v\\
p_t + \nabla \cdot ( gh\vec{u} ) &= q_p
\end{align}\label{eq:linear}
\end{subequations}

Any flavor of the shallow water equations arise from a conservation law, and as such, \eqref{eq:conservative}, \eqref{eq:skewsymmetric}, or \eqref{eq:linear} can be written in the compact form
\begin{equation}
\vec{s} + \nabla \cdot \vec{f} = \vec{q}. \label{eq:conservationlaw}
\end{equation}
The solution vector is represented by $\vec{s}$, $\vec{f}$ is a conservative flux tensor, and $\vec{q}$ is a vector of non-conservative source terms. The derivation of the discrete equations is presented through a discretization of \eqref{eq:conservationlaw}. 

In the applications discussed in this document, we are primarily focused on the Conservative Form of the Shallow Water equations. In all of the benchmarks, we use the \texttt{dipole} example with a fixed unstructured mesh. 


\section{Nodal Discontinuous Galerkin Spatial Discretization}
The NDGSEM discretizes \eqref{eq:conservationlaw} in its weak form. The physical space over which \eqref{eq:conservationlaw} is solved is denoted by $\Omega$. Solutions to \eqref{eq:conservationlaw} are real functions that are piecewise continuous on $\Omega$. This space of functions is denoted $\mathbb{C}_0(\Omega)$, and is defined mathematically
\begin{equation}
\mathbb{C}_0(\Omega) \equiv \left\lbrace \phi(\vec{x}) \in \mathbb{R} : \int_{\Omega} \phi^2 d\Omega < \infty \right\rbrace,
\end{equation}
\textit{`` the set of all functions $\phi$ that are square integrable over the physical space $\Omega$ ''}.

$\mathbb{C}_0(\Omega)$ has an inner product associated with it, defined by
\begin{equation}
(u,v) = \int_{\Omega} uv \hspace{1mm} d\Omega. \label{eq:innerproduct}
\end{equation}
From the definition of the inner product, the \textit{induced norm} of a function that is in $\mathbb{C}_0(\Omega)$ is defined as
\begin{equation}
||u|| = \sqrt{(u,u)}.\label{eq:norm}
\end{equation}
Similar to vectors, the inner-product \eqref{eq:innerproduct} is a measure of the ``common information'' between $u$ and $v$. Two functions are said to be \textit{orthogonal} if
\begin{equation}
(u,v) = 0. \label{eq:orthogonality}
\end{equation}

Any piecewise continuous function can be represented as a linear combination of a \textit{basis functions} that span $\mathbb{C}_0(\Omega)$. The weak form of \eqref{eq:conservationlaw} is obtained by taking the inner product of \eqref{eq:conservationlaw} with each basis function of $\mathbb{C}_0(\Omega)$,  
\begin{equation}
(\vec{s}_t,\phi) + (\nabla \cdot \vec{f}, \phi) = (\vec{s},\phi), \hspace{3mm} \forall \phi \in \mathbb{C}_0(\Omega) \label{eq:step1}
\end{equation}
In Eqs. \eqref{eq:conservative}, \eqref{eq:skewsymmetric}, and \eqref{eq:linear}, the conservative flux depends on the solution. In \eqref{eq:step1}, the divergence of the flux  requires that the solution is at least once differentiable. This differentiability constraint is relaxed in the weak form by performing integration by parts, which moves the differentiability criteria onto the basis function ($\phi$). Performing integrations by parts gives
\begin{equation}
(\vec{s}_t,\phi) + \oint_{\partial \Omega}\phi \vec{f} \cdot \hat{n} \hspace{1mm} dS - ( \vec{f},\nabla \phi) = (\vec{s},\phi), \hspace{3mm} \forall \phi \in \mathbb{C}_0(\Omega) \label{eq:weakform}
\end{equation}


 To develop a discrete set of equations, all of $\mathbb{C}_0(\Omega)$ is approximated by piecewise continuous polynomials of degree $N$, a space we denote $\mathbb{P}^N$. The solution, conservative flux, and the non-conservative source term are approximated by a linear combination of a suitable basis for $\mathbb{P}^N$. Since the solution is piecewise continuous, the domain $\Omega$, is decomposed into a set of non-overlapping elements $\Omega_l$. The integration is  broken into integration over each of the elements,
  \begin{equation}
 \sum_{\kappa=0}^{nEl} \left\lbrace \int_{\Omega_\kappa} (\vec{s}_t + \vec{q} )\phi_\kappa \hspace{1mm} d\Omega_\kappa  - \int_{\Omega_l} \vec{f} \cdot \nabla \phi_\kappa \hspace{1mm} d\Omega_\kappa + \oint_{\partial \Omega^\kappa} \phi_\kappa \vec{f}\cdot \hat{n} \hspace{1mm} d A_\kappa = 0 \right\rbrace, \hspace{3mm} \forall \phi_\kappa \in \mathbb{P}^n. \label{eq:weak-decomp}
  \end{equation}

In the \textit{Discontinuous} Galerkin approximation, the $\phi_l$ are identically zero outside of the $l^{th}$ element, so that the contributions from each element are decoupled (except for the element boundary integration). This feature of DG is called \textit{compact support}. Again, the solution, flux, and source are approximated by a polynomial of degree $N$. We choose to write each term as a linear combination of polynomial basis function; here the Lagrange interpolating polynomials are used,
\begin{subequations}
    \begin{align}
    \vec{s} &\approx I^N[\vec{s}] = \vec{S} =  \sum_{i,j=0}^N \vec{S}_{i,j} l_i(\xi^1) l_j(\xi^2) \\
    \vec{q} &\approx I^N[\vec{q}]= \vec{Q} = \sum_{i,j=0}^N \vec{Q}_{i,j} l_i(\xi^1) l_j(\xi^2) \\
    \vec{f} &\approx I^N[\vec{f}] =\vec{F}= \sum_{i,j=0}^N \vec{F}_{i,j} l_i(\xi^1) l_j(\xi^2)
    \end{align}
 \end{subequations}


The basis functions for $\mathbb{P}^N$ are chosen as each of the Lagrange interpolating polynomials, 
 \begin{equation}
 \phi_{m,n} = l_m(\xi^1) l_n(\xi^2)
 \end{equation}
 With this, equation \eqref{eq:weak-decomp} becomes
   \begin{equation}
  \int_{\Omega^\xi} (\vec{S}^\kappa_t + \vec{Q}^\kappa) \phi_{m,n}  \hspace{1mm} d\Omega^\xi  - \int_{\Omega^\xi} \vec{F}^\kappa \cdot \nabla_{\vec{\xi}} \phi_{m,n}   \hspace{1mm} d\Omega^\xi + \oint_{\partial \Omega^\xi} \phi_{m,n}  \vec{F}^{\kappa,*}  \cdot \hat{n} \hspace{1mm} d A^\xi = 0, \hspace{2mm} m,n=0,1,...,N  \label{eq:weak-decomp-basis}
  \end{equation}
  
The final step is to replace the integrals in \eqref{eq:weak-decomp-basis} with discrete quadrature. For this we use the Legendre-Gauss quadrature, which yields exact integration for each term in \eqref{eq:weak-decomp-basis}. Additionally, the interpolation nodes are specified as the Legendre-Gauss nodes, which simplifies the integration.
 \begin{equation}
 \begin{split}
 \left( J_{m,n} \vec{S}_{m,n} \right)_t =  &-\left[\sum_{i=0}^{N}\hat{D}^{(\xi^1)}_{m,i} \tilde{F}^{(\xi^1)}_{i,n}   + \left( \frac{ l_m(1)}{w^{(\xi^1)}_m} \tilde{F}^{*}(1,\xi^2_n) - \frac{ l_m(-1)}{w^{(\xi^1)}_m} \tilde{F}^{*}(-1,\xi^2_n) \right) \cdot \hat{\xi^1} \right] \\
  &-\left[ \sum_{j=0}^{N}\hat{D}^{(\xi^2)}_{n,j} \tilde{F}^{(\xi^2)}_{m,j}  + \left( \frac{l_n(1)}{w^{(\xi^2)}_n} \tilde{F}^{*}(\xi^1_m,1)  -  \frac{l_n(-1)}{w^{(\xi^2)}_n} \tilde{F}^{*}(\xi^1_m,-1) \right)\cdot \hat{\xi^2}  \right] \\ 
 &+ J_{m,n}\vec{Q}_{m,n}; \hspace{5mm} m,n=0,1,...,N
\end{split} \label{eq:discrete2d_system} 
 \end{equation}

Each element can support curvilinear geometry. Define the mapping from physical space $\vec{x}$ to computational space $\vec{\xi}$ using
  \begin{equation}
  \vec{x} = \vec{x}(\vec{\xi}).\label{eq:mapping}
  \end{equation}
In this case, the solution and the source term are weighted by the Jacobian of the mapping and the flux is rotated to the \textit{contravariant} flux. Introducing mappings that are also approximated by polynomial interpolants introduces additional (spectrally accurate) \textit{aliasing} errors.   Appendix \ref{chap:GeometryTheory} provides the details on the metric terms that are introduced along with the form of the divergence, gradient, and curl under such a mapping.

 Computing the divergence of the conservative flux in this framework can be viewed as calculating a sequence of derivatives in each computational direction. Two steps are required to compute the derivative in each direction. The first is an internal matrix-vector multiply, and the second is computing the weighted Riemann fluxes at the element boundaries. The latter is the only step which requires element-to-element communication. The approximate fluxes are now presented for the systems \eqref{eq:conservative}, \eqref{eq:skewsymmetric}, and \eqref{eq:linear}.

\subsection{Riemann Flux}
\textit{This section needs some attention!}\\
\begin{figure}
\begin{center}
\includegraphics[width=0.4\textwidth]{../figures/normalflux.png}
\caption{ A depiction of the setup for computing the flux across an edge. The flux is split by upwinding the characteristic variables of the Jacobian matrix. }\label{fig:normalflux}
\end{center}
\end{figure}
Regardless of which system we are solving, the DG approximation requires that we compute an estimate of the flux across an element's edge given the solution on either side of the edge. In general, the solution is discontinuous across the edges. Let $\vec{s}_L$ and $\vec{s}_R$ denote the solution to the ``left'' and to the ``right'' of the edge as depicted in Fig. \ref{fig:normalflux}. The goal is to compute the flux across an edge given the left and right states. The conservation law, \eqref{eq:conservationlaw}, can be written
\begin{equation}
\vec{s}_t + \frac{\partial f^n}{\partial \vec{s}}\frac{\partial \vec{s}}{\partial n} = 0,
\end{equation}
where, for the sake of exposition, the source term has been dropped. The flux in the edge-normal direction is $f^n = \vec{f} \cdot \hat{n}$ and the directional derivative of the solution is $\frac{\partial \vec{s}}{\partial n}$. For a short period of time, $\Delta t$,
\begin{equation}
\vec{s}_t + \frac{\partial f}{\partial \vec{s}}|_{t=t_0} \frac{\partial \vec{s}}{\partial n}  = \mathcal{O}(\Delta t). \label{eq:linearizedForm}
\end{equation}
In \eqref{eq:linearizedForm}, the \textit{Jacobian} of the flux, $\frac{\partial f^n}{\partial \vec{s}}$, is evaluated at the fixed time $t=t_0$. For hyperbolic problems, like the shallow water equations, the Jacobian has real eigenvalues and can be diagonalized. Let
\begin{equation}
\frac{\partial f}{\partial \vec{s}}|_{t=t_0} = \boldsymbol{P} \boldsymbol{D} \boldsymbol{P}^{-1},\label{eq:diagonalized}
\end{equation} 
define the diagonalization, where $\boldsymbol{P}$ is a matrix whose columns are the eigenvectors and $\boldsymbol{D}$ is a diagonal matrix whose diagonal elements are the corresponding eigenvalues of the Jacobian. Substituting \eqref{eq:diagonalized} into \eqref{eq:linearizedForm} and multiplying on the left by $\boldsymbol{P}^{-1}$ gives
\begin{equation}
\vec{w}_t + \boldsymbol{D} \boldsymbol{P}^{-1}\frac{\partial \vec{s}}{\partial n}  = \mathcal{O}(\Delta t), \label{eq:diagForm}
\end{equation}
where $\vec{w} = P^{-1}\vec{s}$ are the \textit{characteristic} variables. Equation \eqref{eq:diagForm} can be rewritten, approximately as
\begin{equation}
\vec{w}_t + \boldsymbol{D} \frac{\partial \vec{w}}{\partial n}  \approx \mathcal{O}(\Delta t). \label{eq:diagonalizedForm}
\end{equation}
where variations in the eigenvectors with $n$ have been ignored. Equation \eqref{eq:diagonalizedForm} has approximate solutions
\begin{equation}
w^i = w^i_0( n - \lambda_i (t-t_0)) \label{eq:characteristicSolution}
\end{equation}
where $w^i$ and $\lambda_i$ are the $i^{th}$ eigenvector and eigenvalue, $w^i_0$ is the characteristic variable at time $t=t_0$, and $n$ is the physical distance normal to the edge. To evaluate the flux at the edge, we need to know the solution at the edge ($n=0$). At time $t_0 + \Delta t$,
\begin{equation}
w^i(0, \Delta t) = w^i_0(-\lambda_i\Delta t)
\end{equation}  
so that if $\lambda_i > 0$, the solution depends on the state to the left of the edge, and if $\lambda_i < 0$, the solution depends on the initial state to the right of the edge. Because of this, we split the diagonalization into two components,
\begin{equation}
\frac{\partial f}{\partial \vec{s}}|_{t=t_0} = \boldsymbol{P} \boldsymbol{D}^{+} \boldsymbol{P}^{-1} + \boldsymbol{P} \boldsymbol{D}^{-} \boldsymbol{P}^{-1} = \boldsymbol{A}^{+} + \boldsymbol{A}^{-},\label{eq:diagonalized-split}
\end{equation}
where $\boldsymbol{D}^{+}$ is the diagonal matrix with only positive eigenvalues and $\boldsymbol{D}^{-}$ is the diagonal matrix with only negative eigenvalues. The compact notation $\boldsymbol{A}^{+}$ and $\boldsymbol{A}^{-}$ is used for the Jacobian matrix associated with the splitting of the positive and negative eigenvalues. 

Under similar assumptions used to obtain \eqref{eq:characteristicSolution}, the flux at the boundary can be approximated
\begin{equation}
\vec{f}^n \approx \vec{f}^{n,*} = A^{+}\vec{s}_L + A^{-}\vec{s}_R  \label{eq:fluxApprox}
\end{equation}
It can be shown that
\begin{subequations}
\begin{align}
A^{+} &= \frac{A+|A|}{2} \\
A^{-} &= \frac{A-|A|}{2}
\end{align}
\end{subequations}
so that \eqref{eq:fluxApprox} can be written
\begin{equation}
\vec{f}^{n,*} = \frac{1}{2}\left( \vec{f}^n(\vec{s}_L) + \vec{f}^n(\vec{s}_R) -|A|(\vec{s}_L - \vec{s}_R) \right)\label{eq:RiemannFlux}
\end{equation}
Equation \eqref{eq:RiemannFlux} is the approximate Riemann flux. The choice of approximation for $|A|$ yields different linear flux schemes. In the shallow water software, we use the Lax-Friedrich's flux where $|A|$ is approximated by the maximum eigenvalue using either the left or the right state,
\begin{equation}
|A| = max( \lambda_i(\vec{s}_L), \lambda_i(\vec{s}_R) ).
\end{equation}

\section{Algorithm and Implementation}

This section reports on the original algorithm design, originally based on the work of \citet{Kopriva2009}.

To forward-step the discrete system in Eq. \eqref{eq:discrete2d_system}, the flux divergence and the source terms need to be calculated. The first two lines of \eqref{eq:discrete2d_system} indicate that we need to calculate the flux at each of the interior nodes (for each element) and to estimate the Riemann flux at each of the element boundaries. \citep{Kopriva2009} showed that using the Legendre-Gauss quadrature satisfies the discrete metric identities and therefore does not introduce non-conservative spurious errors due to coordinate mapping. For this reason, and the higher accuracy associated with Gauss Quadrature (as opposed to Gauss-Lobatto), we employ the Legendre-Gauss quadrature. The main drawback with the Legendre-Gauss points is that they do not include the element edges. To calculate the Riemann flux then, we must first interpolate the solution to the element boundaries.

\begin{figure}
\begin{center}
\includegraphics[width=0.6\textwidth]{../figures/geometry/elementsimple.png}
\caption{This schematic depicts where the solution is known (at the blue nodes) within an element; these are the Legendre-Gauss points. The computational coordinate are $s$ and $p$. In this document, the integer $i$ increments the solution in the $s$ direction and $j$ increments the solutions in the $p$ direction. To compute the Riemann Flux, we need to calculate the solution at the element boundaries (at the red nodes). The schematic also indicates how the SELF software references each of the sides of an element. ``South'' refers to the side where $p=-1$, ``North'' $p=1$, ``West'' $s=-1$, and ``East'' $s=1$.}
\end{center}
\end{figure}

\subsection{Interpolation to the Element Boundaries}
Recall that the solution is represented as
\begin{equation}
\vec{S} =  \sum_{i,j=0}^N \vec{S}_{i,j} l_i(s) l_j(p).
\end{equation}
As an example, suppose we want to calculate the solution on the eastern boundary, where $s = 1$, $p = p_n$. Note that the $p_n$ are the interpolation nodes for the Lagrange interpolating polynomials, so that $l_j(p_n) = \delta_{j,n}$, where $\delta_{j,n}$ is the Kronecker Delta function. Then
\begin{subequations}
\begin{align}
 \vec{S}_{east} = \sum_{i=0}^N \vec{S}_{i,n} l_i(1)
 \vec{S}_{west} &= \sum_{i=0}^N \vec{S}_{i,n} l_i(-1) \\
 \vec{S}_{south} &= \sum_{j=0}^N \vec{S}_{m,j} l_j(-1) \\
 \vec{S}_{north} &= \sum_{j=0}^N \vec{S}_{m,j} l_j(1) \label{eq:boundaryInterp}
\end{align}
\end{subequations}

\subsection{Computing the Flux}
Once the solution is known at the boundaries of each of the elements, the boundary flux can be computed using a Riemman flux. To do this, we cycle over the edges in the mesh and calculate the flux across each edge, exchanging the flux with the elements that share common edges. Once we have the flux at the boundary of the elements, we can then calculate the flux divergence using the first two lines of \eqref{eq:discrete2d_system}.


\subsection{Computing the Flux-Divergence}\label{sec:MappedTimeDerivative}

\section{Callgraph of S/R GlobalTimeDerivative}
The subroutine \texttt{GlobalTimeDerivative} is the workhorse of the DGSEM implemented by the SELF. It is comprised of three main steps
\begin{enumerate}
\item Loop over the elements and interpolate the solution to the element's boundaries.
\item Loop over the edges, compute the Riemann Flux, and copy the flux to the abutting elements.
\item Loop over the elements and compute the flux divergence according to \eqref{eq:discrete2d_system}
\end{enumerate}

To begin optimizing the DGSEM-SELF module (for example, with the shallowwater solver) we first make a call-graph of \texttt{GlobalTimeDerivative}, which will indicate where most of the time is spent. The call-graph will be generated here using \texttt{valgrind} with the \texttt{callgrind} tool. A program is written that calls only the \texttt{GlobalTimeDerivative} subroutine after the shallowwater data-structure is constructed. The modules and program are compiled with debugging information turned on using the \texttt{-g} compile-time flag. The program is run underneath valgrind on a Dell-Latitude E6410 Laptop (see Appendix \ref{sec:DellLaptop} for architecture details). The parameters for the shallowwater configuration give $10^{th}$ degree polynomials within the elements of an unstructured mesh. The unstructured mesh is generated from \texttt{SpecMesh+3D} using the control file
\begin{center} \texttt{SELF/examples/shallowwater/dipole/run/box.control}. 
\end{center}
The mesh is stored in the SpecMesh file 
\begin{center}
\texttt{SELF/examples/shallowwater/dipole/run/box.mesh}.
\end{center}
This mesh consists of  489 corner-nodes, 448 elements, and 936 edges and is shown in Fig. \ref{fig:boxmesh}.

\begin{figure}
\begin{center}
\includegraphics[width=0.9\textwidth]{projectFigures/boxmesh.png}
\caption{The unstructured mesh that is used to calculate the flux-divergence for the examples discussed here.}\label{fig:boxmesh}
\end{center}
\end{figure}

The program \texttt{GTD\_Test} is run underneath valgrind with the callgrind tool enabled using the call,
\begin{center}
\texttt{ valgrind --tool=callgrind ./GTD\_Test }
\end{center}
The output of callgrind is visualized using \texttt{kcachegrind}, and is shown in Fig. \ref{fig:OrignalCallGraph}.

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{projectFigures/callgraphOriginal.png}
\caption{The call-graph generated from callgrind and visualized with kcachegrind for the original version of S/R GlobalTimeDerivative for the SELF-shallowwater solver. Immediately, we can see that most of the execution time is spent within the MappedTimeDerivative subroutine.}\label{fig:OrignalCallGraph}
\end{center}
\end{figure}

%\section{Profiles of the Dipole Example}
%In order to determine where our attention should be focused for optimizing the solution algorithm, call-graphs are generated using callgrind and kcachegrind to indicate the subroutines that dominate the program execution. More detailed information about the types of instructions that are being called ( memory access, floating point, vectorization, etc.) is obtained using the Allinea-MAP (V6.0) profiler. The profiles presented here are generated on a \textit{(fill in node information (from cpuinfo and/or lstopo)}. The runtime parameters for this example can be found under \texttt{SELF/examples/shallowwater/dipole/run/shallowater.params} and, for completeness, are shown here
%\begin{verbatim}
%&ModelForm
%ModelFormulation = 'Conservative',
%nCutoff = 8,
%/
%&TimeManagement
%dt = 0.1,
%iterInit = 0,
%nTimeSteps = 1000,
%dumpFreq = 1000,
%/
%&SpaceManagement
%SpecMeshFile = 'box.mesh',
%polyDeg = 10,
%nXElem = 20,
%nYElem = 20,
%nPlot = 20,
%xScale = 4.0D5,
%yScale = 4.0D5,
%/
%&PhysicalParameters
%g = 9.81,
%f0 = 1.0D-4,
%betaX = 0.0,
%betaY = 0.0,
%linearDrag = 0.0,
%/
%&DipoleParameters
%vMax = 1.75,
%x0 = 2.0D5,
%y0 = 205000.0,
%x1 = 2.0D5,
%y1 = 195000.0,
%L  = 1.0D4,
%/
%&SpongeParameters
%Lsponge = 5.0D4,
%rFacMax = 5.0D-2,
%/
%&ShelfParameters
%hMin = 200.0,
%hMax = 3000.0,
%Lshelf = 2.5D5,
%dL = 0.0,
%steepeningCenter = 1.0D6,
%steepeningZoneLength = 5.0D4,
%/
%\end{verbatim} 
%
%The compiler flags are \textit{(list the compiler flags!!)}.
%
%integrate\_sw\_dipole\_boxmesh\_pdeg10\_noOpt\_noOMP.map : \texttt{-g}
%
%integrate\_sw\_dipole\_boxmesh\_pdeg10\_O2\_noOMP.map : \texttt{-O2 -g}
%
%integrate\_sw\_dipole\_boxmesh\_pdeg10\_O3\_noOMP.map : \texttt{-O3 -g}

\clearpage

\section{Suggested Algorithm Improvements}

 \subsection{Calculating the Mapped Time Derivative}
  The multiplication between the internal flux and the derivative matrix require $\mathcal{O}(N^3)$ operations. The internal flux can be represented as a matrix, so that the flux divergence can be computed by a single matrix-matrix multiply.

 \begin{verbatim}
   DO j = 0, N
      DO i = 0, N
         
         Fx = Xflux( solution(i,j) )
         Fy = Yflux( solution(i,j) )
         GetMetricTerms
         [F1(i,j), F2(j,i)] = ContravariantFlux( Fx, Fy, MetricTerms )
        
      ENDDO
   ENDDO
   
   tend = MATMUL( dMat, F1 ) + MATMUL( dMat, F2 )
   
   DO j = 0, N
      DO i = 0, N
         tend(i,j) = tend(i,j)  + ( least(i)*F1east(j) + &
                                    lwest(i)*F1west(j) )/weight(i) + & 
                                  ( lnorth(j)*F2north(i) + &
                                    lsouth(j)*F1south(i) )/weight(j)
      ENDDO
   ENDDO
 \end{verbatim}
 
 \subsection{Boundary Interpolation}
 When interpolating the solutions within each element to the element boundaries, we currently
 follow Algorithm ..., where we loop over each computational direction separately, pull a single dimension array of the solution from memory, and perform a vector-vector product. This procedure follows logically from the 1-D problem and made it trivial to extend the 1-D DGSEM software to 2-D and 3-D. However, in 2-D, this algorithm results in many, very small $\mathcal{O}(80-200 \hspace{1mm} bytes)$ memory accesses that are interrupted by vector-vector products. This sort of low memory access coupled with small floating point operations is pervasive throughout the SELF and can be improved by having a single, larger memory access and a single matrix-vector product. 
 
 Recall that the boundary interpolation procedure is mathematically described by \eqref{eq:boundaryInterp}. If the 2-D array $\vec{S}_{i,j}$ is seen as a matrix, call it $\boldsymbol{S}$, and if we write the Lagrange interpolating polynomials interpolants as vectors, then,
\begin{subequations}
\begin{align}
\vec{S}_{east} &= \boldsymbol{S}^T \vec{l}_{east} \\
\vec{S}_{west} &= \boldsymbol{S}^T \vec{l}_{west} \\
\vec{S}_{south} &= \boldsymbol{S} \vec{l}_{south} \\
\vec{S}_{north} &= \boldsymbol{S} \vec{l}_{north} \label{eq:boundaryInterpMatrixVector}
\end{align}
\end{subequations} 
The boundary interpolation can be condensed further as two matrix-matrix products by combining east and west interpolations, and south and north interpolations,
\begin{subequations}
\begin{align}
   \begin{pmatrix} \vec{S}_{east} & \vec{S}_{west} \end{pmatrix} &= \boldsymbol{S}^T \begin{pmatrix} \vec{l}_{east} & \vec{l}_{west} \end{pmatrix}\\
\begin{pmatrix} \vec{S}_{south} & \vec{S}_{north} \end{pmatrix} &= \boldsymbol{S} \begin{pmatrix} \vec{l}_{south} & \vec{l}_{north} \end{pmatrix}  \label{eq:boundaryInterpMatrixMatrix}
\end{align} 
\end{subequations}
A matrix vector product would require a single solution access per element where we retrieve $Mem = 8*(N+1)^2$ bytes from memory; there are $(N+1)^2$ solution nodal values in each element and we multiply by $8$ assuming that the nodal values are double precision floating point values. Typical values of $N$, the polynomial degree, range from $N=7$ up to $N=15$, so that $Mem = 512\rightarrow 2048$ bytes. Eqs. \eqref{eq:boundaryInterpMatrixVector} requires four separate passes of the solution matrix  and four separate passes of each boundary interpolant array to a matrix-vector product routine. Eqs. \eqref{eq:boundaryInterpMatrixMatrix}, on the other hand, require only two passes of the solution matrix and two passes of pairs interpolant array to a matrix-matrix product routine. Since all of the arrays fit into typical cache memory, an algorithm based off of \eqref{eq:boundaryInterpMatrixMatrix} will have a larger floating point - to - memory access ratio given the fewer passes of the solution and will likely execute faster.

 Current CPU architectures have cache sizes on the order of MB. The memory fetch ($\mathcal{O}(kB)$) for each boundary interpolation is far smaller than current CPU cache sizes ($\mathcal{O}(MB)$). 
 \subsection{Mapping solutions to a plotting mesh}

 
\chapter{Projects}
\section{Algorithm parallelization through OpenMP}

\section{Algorithm parallelization through MPI}

\section{Forcing Vectorization}

\section{Mixed OpenMP and MPI}

\section{Matrix Multiplication on the GPU}

\section{Data Structure Mods for Reducing Memory Access Costs}

\section{Parallel File I/O}



\clearpage

\appendix

\chapter{Computing Platforms}
 This section of the appendix lists the details of the computing platforms that the SELF implementation of the shallowwater solver has been tested on.
 
\section{Dell Latitude E6410 (Quad-Core laptop)}\label{sec:DellLaptop}
  Below is the output from \textit{cat /proc/cpuinfo} for one of the four cores
  \begin{verbatim}
vendor_id	: GenuineIntel
cpu family	: 6
model		: 37
model name	: Intel(R) Core(TM) i7 CPU       M 640  @ 2.80GHz
cpu MHz		: 1199.000
cache size	: 4096 KB
physical id	: 0
siblings	: 4
core id		: 2
cpu cores	: 2
clflush size	: 64
cache_alignment	: 64
address sizes	: 36 bits physical, 48 bits virtual
  \end{verbatim}

\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{projectFigures/dell-latitudee6410.png}
\caption{A graphical representation of the Dell-Latitude E6410 hardware, from \texttt{lstopo}.}
\end{center}
\end{figure}

\pagebreak

\bibliography{hpe-refs}
\bibliographystyle{plainnat}
\end{document}


\section{Nodal Discontinuous Galerkin Discretization}


\section{Comparison with other SEM-Shallow Water Models}
The discretization presented here distinguishes itself from previous shallow water models presented in the literature. The models of \citet{Iskandarani1995} (and Ma1993) make use of the Gauss-Lobatto quadrature points, which were shown in \citet{Kopriva2006} to not satisfy the discrete metric identities and lead to the introduction of spurious modes associated with isoparametric elements. Here, the more accurate Gauss quadrature is used. The increased accuracy and satisfication of the discrete metric identities increases the algorithm cost. Since the Gauss quadrature points do not include the element boundaries, an additional step ( with $\mathcal{O}(N^2)$ operations per element ) is needed to interpolate the solution to the element boundaries before computing Riemann fluxes. An adpative filtering procedure, similar to \citet{Flad2016} is used for maintaining stability when marginally resolved modes violate energy conservation. In this way, the filter lowers the accuracy of the method only in locations where the solution is marginally resolved; the gain in performing the filtering is that numerical stability is maintained. This filtering procedure is different than \citet{Taylor1997} where the filter is applied everywhere at each time step. In the conservative form of the shallow water equations, care was taken in the computation of the bathymetry gradient to guarantee that a motionless fluid remains motionless to machine precision.